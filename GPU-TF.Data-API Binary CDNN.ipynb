{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "regular-baseball",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will install dependencies and display them in the notebook\n",
    "#!pip install -r requirements.txt\n",
    "\n",
    "# Install dependencies in Quiet Mode\n",
    "#!pip install -r -q requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "built-coordination",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.distribute.one_device_strategy.OneDeviceStrategy at 0x2650e9f49a0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pathlib\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nvitop\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "# os.environ[\"TF_GPU_THREAD_MODE\"] = \"gpu_private\" can slow down computation depending on setup and GPU type (developed on GTX 1660)\n",
    "tf.distribute.OneDeviceStrategy(device=\"/gpu:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "attractive-photography",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce GTX 1660, compute capability 7.5\n"
     ]
    }
   ],
   "source": [
    "policy = tf.keras.mixed_precision.Policy(\"mixed_float16\")\n",
    "tf.keras.mixed_precision.experimental.set_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "endless-hydrogen",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = pathlib.Path.cwd()\n",
    "\n",
    "datadir = pathlib.Path(\n",
    "    cwd / 'cats-v-dogs' /'training'\n",
    ")\n",
    "valdir = pathlib.Path(\n",
    "    cwd / 'cats-v-dogs' / 'testing'\n",
    ")\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "logdir = pathlib.Path.cwd() / \"logs\"\n",
    "\n",
    "# if logdir.exists():\n",
    "#     !rmdir /q/s logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "arctic-saturn",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22283\n"
     ]
    }
   ],
   "source": [
    "image_count = len(list(datadir.glob(\"*/*.jpg\")))\n",
    "print(image_count)\n",
    "batch_size = 128\n",
    "img_height = 150\n",
    "img_width = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fixed-awareness",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ds = tf.data.Dataset.list_files(str(datadir / \"*/*.jpg\"), shuffle=False)\n",
    "val_ds = tf.data.Dataset.list_files(str(valdir / \"*/*.jpg\"), shuffle=False)\n",
    "list_ds = list_ds.shuffle(image_count, reshuffle_each_iteration=False)\n",
    "num_train_files = len(list_ds)\n",
    "num_val_files = len(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "sunset-bermuda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'C:\\\\Users\\\\josephdavis\\\\Desktop\\\\Tensorflow notebooks\\\\cats-v-dogs\\\\training\\\\dogs\\\\1148.jpg'\n",
      "b'C:\\\\Users\\\\josephdavis\\\\Desktop\\\\Tensorflow notebooks\\\\cats-v-dogs\\\\training\\\\dogs\\\\5511.jpg'\n",
      "b'C:\\\\Users\\\\josephdavis\\\\Desktop\\\\Tensorflow notebooks\\\\cats-v-dogs\\\\training\\\\cats\\\\9749.jpg'\n",
      "b'C:\\\\Users\\\\josephdavis\\\\Desktop\\\\Tensorflow notebooks\\\\cats-v-dogs\\\\training\\\\cats\\\\5283.jpg'\n",
      "b'C:\\\\Users\\\\josephdavis\\\\Desktop\\\\Tensorflow notebooks\\\\cats-v-dogs\\\\training\\\\cats\\\\11529.jpg'\n",
      "validation\n",
      "b'C:\\\\Users\\\\josephdavis\\\\Desktop\\\\Tensorflow notebooks\\\\cats-v-dogs\\\\testing\\\\cats\\\\100.jpg'\n",
      "b'C:\\\\Users\\\\josephdavis\\\\Desktop\\\\Tensorflow notebooks\\\\cats-v-dogs\\\\testing\\\\cats\\\\10004.jpg'\n",
      "b'C:\\\\Users\\\\josephdavis\\\\Desktop\\\\Tensorflow notebooks\\\\cats-v-dogs\\\\testing\\\\cats\\\\10024.jpg'\n",
      "b'C:\\\\Users\\\\josephdavis\\\\Desktop\\\\Tensorflow notebooks\\\\cats-v-dogs\\\\testing\\\\cats\\\\10038.jpg'\n",
      "b'C:\\\\Users\\\\josephdavis\\\\Desktop\\\\Tensorflow notebooks\\\\cats-v-dogs\\\\testing\\\\cats\\\\10052.jpg'\n"
     ]
    }
   ],
   "source": [
    "for f in list_ds.take(5):\n",
    "    print(f.numpy())\n",
    "print(\"validation\")\n",
    "for f in val_ds.take(5):\n",
    "    print(f.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "graduate-found",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cats' 'dogs']\n"
     ]
    }
   ],
   "source": [
    "class_names = np.array(sorted([item.name for item in datadir.glob(\"*\")]))\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "finished-filter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22283\n",
      "2473\n"
     ]
    }
   ],
   "source": [
    "print(tf.data.experimental.cardinality(list_ds).numpy())\n",
    "print(tf.data.experimental.cardinality(val_ds).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interested-wilson",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Process path functions for creating TF Data Pipeline\n",
    "\n",
    "def get_label(file_path):\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    one_hot = parts[-2] == class_names\n",
    "    return tf.argmax(one_hot)\n",
    "\n",
    "def decode_img(img):\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    return img\n",
    "\n",
    "def process_path(file_path):\n",
    "    label = get_label(file_path)\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = decode_img(img)\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excessive-brush",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF.Data API using map, where the interleave seems to cause input data pipeline slowdown (I think it's my development CPU bottlenecking the multi-thread interleave process)\n",
    "\n",
    "train_ds = list_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
    "val_ds = val_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "# train_ds = list_ds.interleave(\n",
    "#     lambda x: tf.data.Dataset.list_files(str(datadir / \"*/*.jpg\"), shuffle=True),\n",
    "#     num_parallel_calls=AUTOTUNE,\n",
    "#     cycle_length=4,\n",
    "# #     block_length=4,\n",
    "# #     deterministic=False,\n",
    "# ).map(process_path, num_parallel_calls=AUTOTUNE)\n",
    "# val_ds = val_ds.interleave(\n",
    "#     lambda x: tf.data.Dataset.list_files(str(valdir / \"*/*.jpg\"), shuffle=True),\n",
    "#     num_parallel_calls=AUTOTUNE,\n",
    "#     cycle_length=4,\n",
    "# #     block_length=4,\n",
    "# #     deterministic=False,\n",
    "# ).map(process_path, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "# train_ds.cache()\n",
    "# val_ds.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "african-lancaster",
   "metadata": {},
   "outputs": [],
   "source": [
    "#augmentation and resize/rescale preprocess layers\n",
    "data_augmentation = tf.keras.Sequential(\n",
    "    [\n",
    "        #         layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
    "        layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
    "        layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "        layers.experimental.preprocessing.RandomWidth(0.01, interpolation=\"bilinear\"),\n",
    "        layers.experimental.preprocessing.RandomHeight(0.01, interpolation=\"bilinear\"),\n",
    "        layers.experimental.preprocessing.RandomContrast(0.2),\n",
    "        layers.experimental.preprocessing.RandomZoom(0.1),\n",
    "    ]\n",
    ")\n",
    "\n",
    "resize_and_rescale = tf.keras.Sequential(\n",
    "    [\n",
    "        layers.experimental.preprocessing.Resizing(img_height, img_width),\n",
    "        layers.experimental.preprocessing.Rescaling(1.0 / 255),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "going-constitution",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(ds, shuffle=False, augment=False):\n",
    "\n",
    "    # Resize and rescale all datasets.\n",
    "    ds = ds.map(lambda x, y: (resize_and_rescale(x), y), num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "    # cache all datasets after resize/rescale\n",
    "    ds.cache()\n",
    "\n",
    "    # shuffle only Training DS\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(1000)\n",
    "\n",
    "    # Batch all datasets\n",
    "    ds = ds.batch(batch_size)\n",
    "\n",
    "    # augment only training dataset, call cache after augmentation dramatically increases input speed\n",
    "    if augment:\n",
    "        ds = ds.map(\n",
    "            lambda x, y: (data_augmentation(x, training=True), y),\n",
    "            num_parallel_calls=AUTOTUNE,\n",
    "        ).cache()\n",
    "\n",
    "    # Use buffered prefecting on all datasets\n",
    "    return ds.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "\n",
    "train_ds = prepare(train_ds, shuffle=True, augment=True)\n",
    "val_ds = prepare(val_ds)\n",
    "\n",
    "#experimental options for increasing input data pipeline speed further \n",
    "# options = tf.data.Options()\n",
    "# options.experimental_threading.max_intra_op_parallelism = 1\n",
    "# train_ds = train_ds.with_options(options)\n",
    "# val_ds = val_ds.with_options(options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "directed-repeat",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential(\n",
    "    [\n",
    "        # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n",
    "        tf.keras.layers.Conv2D(\n",
    "            16, (3, 3), activation=\"relu\", input_shape=(150, 150, 3)\n",
    "        ),\n",
    "        tf.keras.layers.Conv2D(16, (3, 3), activation=\"relu\"),\n",
    "        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "        tf.keras.layers.Conv2D(32, (3, 3), activation=\"relu\"),\n",
    "        tf.keras.layers.Conv2D(32, (3, 3), activation=\"relu\"),\n",
    "        tf.keras.layers.Conv2D(32, (3, 3), activation=\"relu\"),\n",
    "        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "        #     tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "        # Flatten the results to feed into a DNN\n",
    "        tf.keras.layers.Flatten(),\n",
    "        # 512 neuron hidden layer\n",
    "        tf.keras.layers.Dense(512, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "        #     tf.keras.layers.Dense(32, activation='relu'),\n",
    "        # Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('cats') and 1 for the other ('dogs')\n",
    "        tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=RMSprop(lr=0.001), loss=\"binary_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charming-transportation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create LogDir for Tensorboard writing\n",
    "logs = \"logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "tboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=logs, histogram_freq=1, profile_batch=\"500,520\"\n",
    ")\n",
    "\n",
    "#early stopping callback for when val_loss drops more than 3 epochs in a row, restores best weights from model training\n",
    "callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\", mode=\"auto\", patience=3, restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floating-plate",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=50,\n",
    "    verbose=1,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=[callback, tboard_callback],\n",
    "    # enable steps per epoch and val steps if using tf.data.interleave(map_func, num_parallel_calls).map(process_path)\n",
    "    #     steps_per_epoch=int(num_train_files / batch_size),\n",
    "    #     validation_steps=int(num_val_files / batch_size),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unnecessary-former",
   "metadata": {},
   "outputs": [],
   "source": [
    "#notebook magic for t-board extension loading and calling in-line tboard from logdir\n",
    "\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legal-prefix",
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment for evaluation on validation dataset\n",
    "# model.evaluate(val_ds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
